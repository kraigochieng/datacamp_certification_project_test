{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing requirements\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"recipe_site_traffic_2212.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947, 8)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe</th>\n",
       "      <th>calories</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>category</th>\n",
       "      <th>servings</th>\n",
       "      <th>high_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pork</td>\n",
       "      <td>6</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>35.48</td>\n",
       "      <td>38.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Potato</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>914.28</td>\n",
       "      <td>42.68</td>\n",
       "      <td>3.09</td>\n",
       "      <td>2.88</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>97.03</td>\n",
       "      <td>30.56</td>\n",
       "      <td>38.63</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>27.05</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.53</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe  calories  carbohydrate  sugar  protein   category servings  \\\n",
       "0       1       NaN           NaN    NaN      NaN       Pork        6   \n",
       "1       2     35.48         38.56   0.66     0.92     Potato        4   \n",
       "2       3    914.28         42.68   3.09     2.88  Breakfast        1   \n",
       "3       4     97.03         30.56  38.63     0.02  Beverages        4   \n",
       "4       5     27.05          1.85   0.80     0.53  Beverages        4   \n",
       "\n",
       "  high_traffic  \n",
       "0         High  \n",
       "1         High  \n",
       "2          NaN  \n",
       "3         High  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing identifier column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"recipe\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories        float64\n",
       "carbohydrate    float64\n",
       "sugar           float64\n",
       "protein         float64\n",
       "category         object\n",
       "servings         object\n",
       "high_traffic     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null with \"0\"\n",
    "df[\"high_traffic\"] = df[\"high_traffic\"].fillna(\"0\")\n",
    "# Replace \"High\" with \"1\"\n",
    "df[\"high_traffic\"] = df[\"high_traffic\"].replace(\"High\", \"1\")\n",
    "# COnvert to int\n",
    "df[\"high_traffic\"] = pd.to_numeric(df[\"high_traffic\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>category</th>\n",
       "      <th>servings</th>\n",
       "      <th>high_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pork</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.48</td>\n",
       "      <td>38.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Potato</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>914.28</td>\n",
       "      <td>42.68</td>\n",
       "      <td>3.09</td>\n",
       "      <td>2.88</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.03</td>\n",
       "      <td>30.56</td>\n",
       "      <td>38.63</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.05</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.53</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calories  carbohydrate  sugar  protein   category servings  high_traffic\n",
       "0       NaN           NaN    NaN      NaN       Pork        6             1\n",
       "1     35.48         38.56   0.66     0.92     Potato        4             1\n",
       "2    914.28         42.68   3.09     2.88  Breakfast        1             0\n",
       "3     97.03         30.56  38.63     0.02  Beverages        4             1\n",
       "4     27.05          1.85   0.80     0.53  Beverages        4             0"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories        5.491024\n",
       "carbohydrate    5.491024\n",
       "sugar           5.491024\n",
       "protein         5.491024\n",
       "category        0.000000\n",
       "servings        0.000000\n",
       "high_traffic    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of missing values\n",
    "df.isna().sum() / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>category</th>\n",
       "      <th>servings</th>\n",
       "      <th>high_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pork</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meat</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicken Breast</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meat</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pork</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    calories  carbohydrate  sugar  protein        category servings  \\\n",
       "0        NaN           NaN    NaN      NaN            Pork        6   \n",
       "23       NaN           NaN    NaN      NaN            Meat        2   \n",
       "48       NaN           NaN    NaN      NaN  Chicken Breast        4   \n",
       "82       NaN           NaN    NaN      NaN            Meat        4   \n",
       "89       NaN           NaN    NaN      NaN            Pork        6   \n",
       "\n",
       "    high_traffic  \n",
       "0              1  \n",
       "23             0  \n",
       "48             0  \n",
       "82             1  \n",
       "89             1  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"calories\"].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that `calories`, `carbohydrate`, `sugar`, `protein` always miss together\n",
    "\n",
    "My strategy to fill in null values\n",
    "\n",
    "1. Split rows based on `category`\n",
    "2. Plot distributions of columns above to determine what measure of central tendency will be used to impute i.e mean, mode, median.\n",
    "\n",
    "-   Plotting is to check for _skew_ and _modality_\n",
    "\n",
    "3. Impute accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_values = [\"calories\", \"carbohydrate\", \"sugar\", \"protein\"]\n",
    "\n",
    "# for column in columns_with_missing_values:\n",
    "#     sns.kdeplot(x=df[column], hue=df[\"category\"], fill=True)\n",
    "#     plt.title(f\"Distribution of {column} per food category\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is left skewed for all food categories, the median shall be used for imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)\n",
    "for column in columns_with_missing_values:\n",
    "    df[column] = df[column].fillna(df[column].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling duplicate values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(23)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are duplicate values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True, keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate values removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking class imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_traffic\n",
       "1    0.601\n",
       "0    0.399\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"high_traffic\"].value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is fairly balanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check distributions of categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# categorical_columns_df = df.loc[:, categorical_columns]\n",
    "\n",
    "# categorical_columns_df.loc[:, \"high_traffic\"] = df.loc[:, \"high_traffic\"]\n",
    "\n",
    "# for column in categorical_columns:\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "#     sns.countplot(ax=axes[0], x=categorical_columns_df[column], stat=\"percent\")\n",
    "#     axes[0].set_title(f\"Count of {column}\")\n",
    "#     axes[0].tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "#     sns.countplot(\n",
    "#         ax=axes[1],\n",
    "#         x=categorical_columns_df[column],\n",
    "#         hue=df[\"high_traffic\"],\n",
    "#         stat=\"percent\",\n",
    "#     )\n",
    "\n",
    "#     axes[1].set_title(f\"Count of {column} per high traffic\")\n",
    "#     axes[1].tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking distributions of numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=[\"float64\"]).columns\n",
    "# print(numerical_columns)\n",
    "# numerical_columns_df = df.loc[:, numerical_columns]\n",
    "# numerical_columns_df.loc[:, \"high_traffic\"] = df.loc[:, \"high_traffic\"]\n",
    "\n",
    "# for column in numerical_columns:\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "#     sns.histplot(ax=axes[0], x=numerical_columns_df[column], kde=True, stat=\"percent\")\n",
    "#     skew = numerical_columns_df[column].skew()\n",
    "#     axes[0].set_title(f\"Percent of {column}\")\n",
    "#     axes[0].tick_params(axis=\"x\", labelrotation=90)\n",
    "#     axes[0].text(\n",
    "#         0.5, 0.5, f\"Skew: {skew:.3f}\", transform=axes[0].transAxes, fontsize=12\n",
    "#     )\n",
    "#     sns.histplot(\n",
    "#         ax=axes[1],\n",
    "#         x=numerical_columns_df[column],\n",
    "#         hue=df[\"high_traffic\"],\n",
    "#         kde=True,\n",
    "#         stat=\"percent\"\n",
    "#     )\n",
    "\n",
    "#     axes[1].set_title(f\"Percent of {column} per high traffic\")\n",
    "#     axes[1].tick_params(axis=\"x\", labelrotation=90)\n",
    "#     axes[1].text(\n",
    "#         0.5, 0.5, f\"Skew: {skew:.3f}\", transform=axes[1].transAxes, fontsize=12\n",
    "#     )\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in categorical_columns:\n",
    "    df[f\"{column}_encoded\"] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "df = df.drop(columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_columns = df.columns.to_list()\n",
    "# scatter_columns.remove(\"high_traffic\")\n",
    "# scatter_columns.remove(\"category_encoded\")\n",
    "\n",
    "# for column in scatter_columns:\n",
    "#     sns.scatterplot(x=df[column], y=df[\"category_encoded\"], hue=df[\"high_traffic\"], alpha=0.5)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxcox transformation not possible for protein\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import boxcox, yeojohnson\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "numerical_transformation_df = pd.DataFrame()\n",
    "\n",
    "for column in numerical_columns:\n",
    "    numerical_transformation_df[f\"log_{column}\"] = np.log1p(df[column])\n",
    "    numerical_transformation_df[f\"sqrt_{column}\"] = np.sqrt(df[column])\n",
    "    if df[column].min() > 0:\n",
    "        numerical_transformation_df[f\"boxcox_{column}\"], _ = boxcox(df[column])\n",
    "    else:\n",
    "        print(f\"Boxcox transformation not possible for {column}\")\n",
    "    numerical_transformation_df[f\"yeojohnson_{column}\"], _ = yeojohnson(df[column])\n",
    "\n",
    "    qt = QuantileTransformer(\n",
    "        output_distribution=\"normal\", random_state=42, n_quantiles=100\n",
    "    )\n",
    "    numerical_transformation_df[f\"quantile_{column}\"] = qt.fit_transform(\n",
    "        df[column].values.reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "# for column in numerical_transformation_df.columns:\n",
    "#     sns.histplot(x=numerical_transformation_df[column], kde=True)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         KS Statistic  P-Value\n",
      "log_calories                  0.08768  0.00000\n",
      "sqrt_calories                 0.07177  0.00014\n",
      "boxcox_calories               0.02429  0.63763\n",
      "yeojohnson_calories           0.02606  0.54799\n",
      "quantile_calories             0.01804  0.91888\n",
      "log_carbohydrate              0.05374  0.00926\n",
      "sqrt_carbohydrate             0.08480  0.00000\n",
      "boxcox_carbohydrate           0.02467  0.61845\n",
      "yeojohnson_carbohydrate       0.03220  0.28737\n",
      "quantile_carbohydrate         0.01789  0.92363\n",
      "log_sugar                     0.03890  0.11887\n",
      "sqrt_sugar                    0.12115  0.00000\n",
      "boxcox_sugar                  0.03424  0.22359\n",
      "yeojohnson_sugar              0.04264  0.06752\n",
      "quantile_sugar                0.01915  0.88050\n",
      "log_protein                   0.04863  0.02447\n",
      "sqrt_protein                  0.10724  0.00000\n",
      "yeojohnson_protein            0.04827  0.02611\n",
      "quantile_protein              0.01904  0.88463\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "ks_test_results = dict()\n",
    "for transformation in numerical_transformation_df.columns:\n",
    "    standardized_data = (\n",
    "        numerical_transformation_df[transformation]\n",
    "        - numerical_transformation_df[transformation].mean()\n",
    "    ) / numerical_transformation_df[transformation].std()\n",
    "    ks_stat, ks_p_value = kstest(standardized_data, \"norm\")\n",
    "    ks_test_results[transformation] = (ks_stat, ks_p_value)\n",
    "\n",
    "\n",
    "ks_test_results_df = pd.DataFrame.from_dict(\n",
    "    ks_test_results, orient=\"index\", columns=[\"KS Statistic\", \"P-Value\"]\n",
    ")\n",
    "print(ks_test_results_df.round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high_traffic</th>\n",
       "      <th>category_encoded</th>\n",
       "      <th>servings_encoded</th>\n",
       "      <th>quantile_calories</th>\n",
       "      <th>quantile_carbohydrate</th>\n",
       "      <th>quantile_sugar</th>\n",
       "      <th>quantile_protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.381214</td>\n",
       "      <td>0.545544</td>\n",
       "      <td>-1.271127</td>\n",
       "      <td>-1.168949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.161859</td>\n",
       "      <td>0.656545</td>\n",
       "      <td>-0.281338</td>\n",
       "      <td>-0.744574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.775762</td>\n",
       "      <td>0.321109</td>\n",
       "      <td>1.682867</td>\n",
       "      <td>-2.471148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.521998</td>\n",
       "      <td>-1.563081</td>\n",
       "      <td>-1.153283</td>\n",
       "      <td>-1.388335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   high_traffic  category_encoded  servings_encoded  quantile_calories  \\\n",
       "0             1                 8                 4           0.000000   \n",
       "1             1                 9                 2          -1.381214   \n",
       "2             0                 1                 0           1.161859   \n",
       "3             1                 0                 2          -0.775762   \n",
       "4             0                 0                 2          -1.521998   \n",
       "\n",
       "   quantile_carbohydrate  quantile_sugar  quantile_protein  \n",
       "0               0.000000        0.000000          0.000000  \n",
       "1               0.545544       -1.271127         -1.168949  \n",
       "2               0.656545       -0.281338         -0.744574  \n",
       "3               0.321109        1.682867         -2.471148  \n",
       "4              -1.563081       -1.153283         -1.388335  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_numerical_columns = numerical_transformation_df.filter(like=\"quantile\")\n",
    "\n",
    "df = pd.concat([df, transformed_numerical_columns], axis=1)\n",
    "df = df.drop(columns=numerical_columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [high_traffic, category_encoded, servings_encoded, quantile_calories, quantile_carbohydrate, quantile_sugar, quantile_protein]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "numerical_columns = transformed_numerical_columns.columns.to_list()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "print(df[df[\"high_traffic\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_encoded</th>\n",
       "      <th>servings_encoded</th>\n",
       "      <th>quantile_calories</th>\n",
       "      <th>quantile_carbohydrate</th>\n",
       "      <th>quantile_sugar</th>\n",
       "      <th>quantile_protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category_encoded</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052497</td>\n",
       "      <td>0.089020</td>\n",
       "      <td>0.085571</td>\n",
       "      <td>-0.135607</td>\n",
       "      <td>0.135089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servings_encoded</th>\n",
       "      <td>0.052497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025021</td>\n",
       "      <td>-0.038433</td>\n",
       "      <td>-0.017345</td>\n",
       "      <td>-0.028647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_calories</th>\n",
       "      <td>0.089020</td>\n",
       "      <td>-0.025021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031610</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>0.196010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_carbohydrate</th>\n",
       "      <td>0.085571</td>\n",
       "      <td>-0.038433</td>\n",
       "      <td>-0.031610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>0.032585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_sugar</th>\n",
       "      <td>-0.135607</td>\n",
       "      <td>-0.017345</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_protein</th>\n",
       "      <td>0.135089</td>\n",
       "      <td>-0.028647</td>\n",
       "      <td>0.196010</td>\n",
       "      <td>0.032585</td>\n",
       "      <td>-0.084268</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       category_encoded  servings_encoded  quantile_calories  \\\n",
       "category_encoded               1.000000          0.052497           0.089020   \n",
       "servings_encoded               0.052497          1.000000          -0.025021   \n",
       "quantile_calories              0.089020         -0.025021           1.000000   \n",
       "quantile_carbohydrate          0.085571         -0.038433          -0.031610   \n",
       "quantile_sugar                -0.135607         -0.017345          -0.074115   \n",
       "quantile_protein               0.135089         -0.028647           0.196010   \n",
       "\n",
       "                       quantile_carbohydrate  quantile_sugar  quantile_protein  \n",
       "category_encoded                    0.085571       -0.135607          0.135089  \n",
       "servings_encoded                   -0.038433       -0.017345         -0.028647  \n",
       "quantile_calories                  -0.031610       -0.074115          0.196010  \n",
       "quantile_carbohydrate               1.000000        0.014505          0.032585  \n",
       "quantile_sugar                      0.014505        1.000000         -0.084268  \n",
       "quantile_protein                    0.032585       -0.084268          1.000000  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix_columns = df.columns.to_list()\n",
    "correlation_matrix_columns.remove(\"high_traffic\")\n",
    "\n",
    "df[correlation_matrix_columns].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No features are redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE done...\n",
      "\n",
      "Optimal number of features: 3\n",
      "\n",
      "Selected features\n",
      "=================\n",
      "Column: category_encoded, Rank: 1, Selected: True\n",
      "Column: quantile_calories, Rank: 1, Selected: True\n",
      "Column: quantile_protein, Rank: 1, Selected: True\n",
      "\n",
      "Not selected features\n",
      "=====================\n",
      "Column: servings_encoded, Rank: 4, Selected: False\n",
      "Column: quantile_carbohydrate, Rank: 2, Selected: False\n",
      "Column: quantile_sugar, Rank: 3, Selected: False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = df.drop(columns=[\"high_traffic\"])\n",
    "y = df[\"high_traffic\"]\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    min_samples_split=40,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    ccp_alpha=0.015,\n",
    ")\n",
    "\n",
    "rfe = RFECV(\n",
    "    estimator=rf_classifier,\n",
    "    cv=StratifiedKFold(5),\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    # min_features_to_select=3,\n",
    ")\n",
    "rfe.fit(X, y)\n",
    "\n",
    "print(\"RFE done...\")\n",
    "print()\n",
    "# Get the optimal number of features\n",
    "print(\"Optimal number of features: %d\" % rfe.n_features_)\n",
    "print()\n",
    "\n",
    "selected_features = []\n",
    "print(\"Selected features\")\n",
    "print(\"=================\")\n",
    "for i, col in zip(range(X.shape[1]), X.columns):\n",
    "    if rfe.support_[i]:\n",
    "        selected_features.append(col)\n",
    "        print(f\"Column: {col}, Rank: {rfe.ranking_[i]}, Selected: {rfe.support_[i]}\")\n",
    "\n",
    "print()\n",
    "print(\"Not selected features\")\n",
    "print(\"=====================\")\n",
    "for i, col in zip(range(X.shape[1]), X.columns):\n",
    "    if not rfe.support_[i]:\n",
    "        print(f\"Column: {col}, Rank: {rfe.ranking_[i]}, Selected: {rfe.support_[i]}\")\n",
    "\n",
    "X = X[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only `category_encoded` is chosen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_transformed = pca.fit_transform(df[numerical_columns])\n",
    "pca_columns = [f\"pca_{i}\" for i in range(pca_transformed.shape[1])]\n",
    "df_pca = pd.DataFrame(pca_transformed, columns=pca_columns, index=df.index)\n",
    "\n",
    "# Combine the PCA-transformed columns with the original DataFrame\n",
    "df = pd.concat([df.drop(columns=numerical_columns), df_pca], axis=1)\n",
    "X = df.drop(columns=[\"high_traffic\"])\n",
    "y = df[\"high_traffic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kraigochieng/miniconda3/envs/datacamp_project_test/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/kraigochieng/miniconda3/envs/datacamp_project_test/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/kraigochieng/miniconda3/envs/datacamp_project_test/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/kraigochieng/miniconda3/envs/datacamp_project_test/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/kraigochieng/miniconda3/envs/datacamp_project_test/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/kraigochieng/miniconda3/envs/datacamp_project_test/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for AdaBoost:\n",
      "--------------------\n",
      "{}\n",
      "\n",
      "Best parameters found for RandomForest:\n",
      "--------------------\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "Best parameters found for LogisticRegression:\n",
      "--------------------\n",
      "{'C': 1, 'penalty': 'l2'}\n",
      "\n",
      "Best parameters found for SVC:\n",
      "--------------------\n",
      "{'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Best parameters found for KNeighbours:\n",
      "--------------------\n",
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "\n",
      "Best parameters found for NaiveBayes:\n",
      "--------------------\n",
      "{}\n",
      "\n",
      "Evaluation: for AdaBoost\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76        74\n",
      "           1       0.83      0.86      0.85       111\n",
      "\n",
      "    accuracy                           0.82       185\n",
      "   macro avg       0.81      0.80      0.81       185\n",
      "weighted avg       0.82      0.82      0.82       185\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "--------------------\n",
      "[[55 19]\n",
      " [15 96]]\n",
      "\n",
      "Root Mean Squared Error\n",
      "--------------------\n",
      "0.43\n",
      "\n",
      "Evaluation: for RandomForest\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        74\n",
      "           1       0.87      0.86      0.86       111\n",
      "\n",
      "    accuracy                           0.84       185\n",
      "   macro avg       0.83      0.83      0.83       185\n",
      "weighted avg       0.84      0.84      0.84       185\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "--------------------\n",
      "[[60 14]\n",
      " [16 95]]\n",
      "\n",
      "Root Mean Squared Error\n",
      "--------------------\n",
      "0.4\n",
      "\n",
      "Evaluation: for LogisticRegression\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79        74\n",
      "           1       0.86      0.86      0.86       111\n",
      "\n",
      "    accuracy                           0.83       185\n",
      "   macro avg       0.83      0.83      0.83       185\n",
      "weighted avg       0.83      0.83      0.83       185\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "--------------------\n",
      "[[59 15]\n",
      " [16 95]]\n",
      "\n",
      "Root Mean Squared Error\n",
      "--------------------\n",
      "0.41\n",
      "\n",
      "Evaluation: for SVC\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77        74\n",
      "           1       0.84      0.86      0.85       111\n",
      "\n",
      "    accuracy                           0.82       185\n",
      "   macro avg       0.81      0.81      0.81       185\n",
      "weighted avg       0.82      0.82      0.82       185\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "--------------------\n",
      "[[56 18]\n",
      " [16 95]]\n",
      "\n",
      "Root Mean Squared Error\n",
      "--------------------\n",
      "0.43\n",
      "\n",
      "Evaluation: for KNeighbours\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74        74\n",
      "           1       0.82      0.86      0.84       111\n",
      "\n",
      "    accuracy                           0.80       185\n",
      "   macro avg       0.79      0.79      0.79       185\n",
      "weighted avg       0.80      0.80      0.80       185\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "--------------------\n",
      "[[53 21]\n",
      " [16 95]]\n",
      "\n",
      "Root Mean Squared Error\n",
      "--------------------\n",
      "0.45\n",
      "\n",
      "Evaluation: for NaiveBayes\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        74\n",
      "           1       0.70      1.00      0.83       111\n",
      "\n",
      "    accuracy                           0.75       185\n",
      "   macro avg       0.85      0.68      0.68       185\n",
      "weighted avg       0.82      0.75      0.71       185\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "--------------------\n",
      "[[ 27  47]\n",
      " [  0 111]]\n",
      "\n",
      "Root Mean Squared Error\n",
      "--------------------\n",
      "0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    root_mean_squared_error,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "classifiers = {\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"RandomForest\": rf_classifier,\n",
    "    \"LogisticRegression\": LogisticRegression(solver=\"liblinear\", random_state=42),\n",
    "    \"SVC\": SVC(random_state=42),\n",
    "    \"KNeighbours\": KNeighborsClassifier(),\n",
    "    \"NaiveBayes\": BernoulliNB(),\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"AdaBoost\": {},\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [100, 200, 300],  # Number of trees in the forest\n",
    "        \"max_depth\": [None, 5, 6],  # Maximum depth of the trees\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"gamma\": [1, 0.1, 0.01, 0.001],\n",
    "        \"kernel\": [\"rbf\", \"linear\"],\n",
    "    },\n",
    "    \"KNeighbours\": {\n",
    "        \"n_neighbors\": [3, 5, 11, 19],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "    },\n",
    "    \"NaiveBayes\": {},\n",
    "}\n",
    "\n",
    "best_estimators = dict()\n",
    "\n",
    "for classifier_name in classifiers.keys():\n",
    "    estimator = classifiers[classifier_name]\n",
    "    param_grid = param_grids[classifier_name]\n",
    "\n",
    "    search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    search.fit(X=X_train, y=y_train)\n",
    "\n",
    "    print(f\"Best parameters found for {classifier_name}:\")\n",
    "    print(\"-\" * 20)\n",
    "    pprint(search.best_params_)\n",
    "    print()\n",
    "\n",
    "    best_estimators[classifier_name] = search.best_estimator_\n",
    "\n",
    "\n",
    "# Best parameters found\n",
    "for estimator_name, estimator in best_estimators.items():\n",
    "    print(f\"Evaluation: for {estimator_name}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    y_pred = estimator.predict(X_test)\n",
    "\n",
    "    print()\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\"-\" * 20)\n",
    "    print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "    print()\n",
    "\n",
    "    print(\"Root Mean Squared Error\")\n",
    "    print(\"-\" * 20)\n",
    "    print(round(root_mean_squared_error(y_true=y_test, y_pred=y_pred), 2))\n",
    "    print()\n",
    "\n",
    "    if estimator_name == \"RandomForest\":\n",
    "        best_tree = estimator.estimators_[0]\n",
    "        dot_data = export_graphviz(\n",
    "            best_tree,\n",
    "            out_file=None,\n",
    "            feature_names=X.columns,\n",
    "            class_names=list(map(str, y.unique().tolist())),\n",
    "            filled=True,\n",
    "            rounded=True,\n",
    "            special_characters=True,\n",
    "        )\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render(\"best_tree\")\n",
    "        graph.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree drawing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "# from sklearn.tree import export_graphviz\n",
    "\n",
    "# best_tree = best_rf.estimators_[0]\n",
    "# dot_data = export_graphviz(\n",
    "#     best_tree,\n",
    "#     out_file=None,\n",
    "#     feature_names=X.columns,\n",
    "#     class_names=list(map(str, y.unique().tolist())),\n",
    "#     filled=True,\n",
    "#     rounded=True,\n",
    "#     special_characters=True,\n",
    "# )\n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph.render(\"best_tree\")\n",
    "# graph.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacamp_project_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
